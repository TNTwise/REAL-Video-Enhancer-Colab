{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# File Settings\n",
        "INPUT_FILE = \"input.mp4\"\n",
        "OUTPUT_FILE = \"output.mp4\"\n",
        "\n",
        "# Interpolate Settings\n",
        "\n",
        "# https://github.com/TNTwise/real-video-enhancer-models/releases/tag/models/ is where all model files for RVE are stored\n",
        "# you can download them from there, or try custom models from https://openmodeldb.info/\n",
        "\n",
        "INTERPOLATE_MODEL = \"https://github.com/TNTwise/real-video-enhancer-models/releases/download/models/rife4.26.pkl\" # {(link to model path), None}\n",
        "INTERPOLATE_FACTOR = 2\n",
        "SCENE_DETECT_METHOD = \"pyscenedetect\"\n",
        "SCENE_DETECT_SENSATIVITY = \"3.5\" # {0 - 9.9} lower is more sensative\n",
        "\n",
        "# Upscale Settings\n",
        "UPSCALE_MODEL = \"https://github.com/TNTwise/real-video-enhancer-models/releases/download/models/2x_ModernSpanimationV2.pth\" # {(link to model path), None}\n",
        "\n",
        "# FFMpeg Settings\n",
        "ENCODER = \"libx264\" # {libx264,libx265,vp9,av1,prores,ffv1,x264_vulkan,x264_nvenc,x265_nvenc}\n",
        "\n",
        "# Backend Settings\n",
        "BACKEND = \"tensorrt\" # {tensorrt, pytorch} TensorRT is fastest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# will move output file to drive when done for permident storage\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i7UVVPrHpdW"
      },
      "outputs": [],
      "source": [
        "!rm -rf real-video-enhancer/\n",
        "!git clone https://github.com/tntwise/real-video-enhancer --branch 2.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DAndfQ0KIbx"
      },
      "outputs": [],
      "source": [
        "\n",
        "!mkdir real-video-enhancer/models/\n",
        "origdir = os.getcwd()\n",
        "os.chdir(\"real-video-enhancer/models/\")\n",
        "\n",
        "def has_model(model: str):\n",
        "    return model and model.lower() != \"None\"\n",
        "\n",
        "def download_model(model: str):\n",
        "    if has_model(model):\n",
        "        os.system(f\"wget {model}\")\n",
        "\n",
        "download_model(INTERPOLATE_MODEL)\n",
        "download_model(UPSCALE_MODEL)\n",
        "os.chdir(origdir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhG0D85MIXRA"
      },
      "outputs": [],
      "source": [
        "!pip install  --pre --extra-index-url https://download.pytorch.org/whl/test/cu126 -r real-video-enhancer/backend/requirements.txt\n",
        "!cd real-video-enhancer && mkdir bin/ && cd bin && wget https://github.com/TNTwise/real-video-enhancer-models/releases/download/ffmpeg-colab/ffmpeg && chmod +x ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1Kz_PTJb3B_"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "usage: rve-backend.py [-h] [-i INPUT] [-o OUTPUT] [-l OVERLAP] [-b BACKEND] [--upscale_model UPSCALE_MODEL]\n",
        "                      [--interpolate_model INTERPOLATE_MODEL] [--interpolate_factor INTERPOLATE_FACTOR]\n",
        "                      [--precision PRECISION] [--tensorrt_opt_profile TENSORRT_OPT_PROFILE]\n",
        "                      [--scene_detect_method SCENE_DETECT_METHOD] [--scene_detect_threshold SCENE_DETECT_THRESHOLD]\n",
        "                      [--overwrite] [--border_detect] [--crf CRF]\n",
        "                      [--video_encoder_preset {libx264,libx265,vp9,av1,prores,ffv1,x264_vulkan,x264_nvenc,x265_nvenc,av1_nvenc,x264_vaapi,x265_vaapi,av1_vaapi}]\n",
        "                      [--video_pixel_format {yuv420p,yuv422p,yuv444p,yuv420p10le,yuv422p10le,yuv444p10le}]\n",
        "                      [--audio_encoder_preset {aac,libmp3lame,opus,copy_audio}]\n",
        "                      [--subtitle_encoder_preset {srt,ass,webvtt,copy_subtitle}] [--audio_bitrate AUDIO_BITRATE]\n",
        "                      [--custom_encoder CUSTOM_ENCODER] [--tilesize TILESIZE] [--pytorch_gpu_id PYTORCH_GPU_ID]\n",
        "                      [--ncnn_gpu_id NCNN_GPU_ID] [--benchmark] [--UHD_mode] [--slomo_mode] [--hdr_mode]\n",
        "                      [--dynamic_scaled_optical_flow] [--ensemble]\n",
        "                      [--preview_shared_memory_id PREVIEW_SHARED_MEMORY_ID] [--output_to_mpv] [--list_backends]\n",
        "                      [--pause_shared_memory_id PAUSE_SHARED_MEMORY_ID]\n",
        "                      [--upscale_output_resolution UPSCALE_OUTPUT_RESOLUTION]\n",
        "\n",
        "Backend to RVE, used to upscale and interpolate videos\n",
        "\n",
        "options:\n",
        "  -h, --help            show this help message and exit\n",
        "  -i INPUT, --input INPUT\n",
        "                        input video path\n",
        "  -o OUTPUT, --output OUTPUT\n",
        "                        output video path or PIPE\n",
        "  -l OVERLAP, --overlap OVERLAP\n",
        "                        overlap size on tiled rendering (default=10)\n",
        "  -b BACKEND, --backend BACKEND\n",
        "                        backend used to upscale image. (pytorch/ncnn/tensorrt/directml, default=pytorch)\n",
        "  --upscale_model UPSCALE_MODEL\n",
        "                        Direct path to upscaling model, will automatically upscale if model is valid.\n",
        "  --interpolate_model INTERPOLATE_MODEL\n",
        "                        Direct path to interpolation model, will automatically interpolate if model is valid.\n",
        "                        (Downloadable Options: [rife46, rife47, rife415, rife418, rife420, rife422, rife422lite]))\n",
        "  --interpolate_factor INTERPOLATE_FACTOR\n",
        "                        Multiplier for interpolation, will round up to nearest integer for interpolation but the fps\n",
        "                        will be correct\n",
        "  --precision PRECISION\n",
        "                        sets precision for model, (auto/float16/float32, default=auto)\n",
        "  --tensorrt_opt_profile TENSORRT_OPT_PROFILE\n",
        "                        sets tensorrt optimization profile for model, (1/2/3/4/5, default=3)\n",
        "  --scene_detect_method SCENE_DETECT_METHOD\n",
        "                        Scene change detection to avoid interpolating transitions. (options=mean, mean_segmented,\n",
        "                        none) Mean segmented splits up an image, and if an arbitrary number of segments changes are\n",
        "                        detected within the segments, it will trigger a scene change. (lower sensativity thresholds\n",
        "                        are not recommended)\n",
        "  --scene_detect_threshold SCENE_DETECT_THRESHOLD\n",
        "                        Scene change detection sensitivity, lower number means it has a higher chance of detecting\n",
        "                        scene changes, with risk of detecting too many.\n",
        "  --overwrite           Overwrite output video if it already exists.\n",
        "  --border_detect       Detects current borders and removes them, useful for removing black bars.\n",
        "  --crf CRF             Constant rate factor for videos, lower setting means higher quality.\n",
        "  --video_encoder_preset {libx264,libx265,vp9,av1,prores,ffv1,x264_vulkan,x264_nvenc,x265_nvenc,av1_nvenc,x264_vaapi,x265_vaapi,av1_vaapi}\n",
        "                        encoder preset that sets default encoder settings useful for hardware encoders.\n",
        "  --video_pixel_format {yuv420p,yuv422p,yuv444p,yuv420p10le,yuv422p10le,yuv444p10le}\n",
        "                        pixel format for output video\n",
        "  --audio_encoder_preset {aac,libmp3lame,opus,copy_audio}\n",
        "                        encoder preset that sets default encoder settings\n",
        "  --subtitle_encoder_preset {srt,ass,webvtt,copy_subtitle}\n",
        "                        encoder preset that sets default encoder settings\n",
        "  --audio_bitrate AUDIO_BITRATE\n",
        "                        bitrate for audio if preset is used\n",
        "  --custom_encoder CUSTOM_ENCODER\n",
        "                        custom encoder\n",
        "  --tilesize TILESIZE   upscale images in smaller chunks, default is the size of the input video\n",
        "  --pytorch_gpu_id PYTORCH_GPU_ID\n",
        "                        GPU ID for pytorch backend, default is 0\n",
        "  --ncnn_gpu_id NCNN_GPU_ID\n",
        "                        GPU ID for ncnn backend, default is 0\n",
        "  --benchmark           Benchmark without saving video\n",
        "  --UHD_mode            Lowers the resoltion flow is calculated at, speeding up model and saving vram. Helpful for\n",
        "                        higher resultions.\n",
        "  --slomo_mode          Instead of increasing framerate, it will remain the same while just increasing the length of\n",
        "                        the video.\n",
        "  --hdr_mode            Appends ffmpeg command to re encode with hdr colorspace\n",
        "  --dynamic_scaled_optical_flow\n",
        "                        Scale the optical flow based on the difference between frames, currently only works with the\n",
        "                        pytorch backend.\n",
        "  --ensemble            Use ensemble when interpolating if the model supports it.\n",
        "  --preview_shared_memory_id PREVIEW_SHARED_MEMORY_ID\n",
        "                        Memory ID to share preview on\n",
        "  --output_to_mpv       Outputs to mpv instead of an output file (requires mpv to be installed)\n",
        "  --list_backends       list out available backends\n",
        "  --pause_shared_memory_id PAUSE_SHARED_MEMORY_ID\n",
        "                        File to store paused state (True means paused, False means unpaused)\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzEEIflBLpAG"
      },
      "outputs": [],
      "source": [
        "#example upscale/denoise command\n",
        "# It is recommended to use  --video_encoder_preset x264_nvenc\n",
        "def build_backend_command():\n",
        "    command = f'cd real-video-enhancer/ && python3 backend/rve-backend.py -i \"{INPUT_FILE}\" -o \"{OUTPUT_FILE}\" -b {BACKEND} '\n",
        "    if has_model(UPSCALE_MODEL):\n",
        "        command += f\"--upscale_model models/{UPSCALE_MODEL}\"\n",
        "    if has_model(INTERPOLATE_MODEL):\n",
        "        command += f\"--interpolate_model models/{INTERPOLATE_MODEL} \"\n",
        "        command += f\"--interpolate_factor {INTERPOLATE_FACTOR} \"\n",
        "        command += f\"--scene_detect_method {SCENE_DETECT_METHOD} \"\n",
        "        command += f\"--scene_detect_sensativity {SCENE_DETECT_SENSATIVITY} \"\n",
        "    \n",
        "\n",
        "os.system(f' -i \"../{INPUT_FILE}\" -o \"../{OUTPUT_FILE}\" --upscale_model models/{UPSCALE_MODEL} --backend {BACKEND} --video_encoder_preset x264_nvenc')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mount drive and move output there for permadent storage\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Source file path in Colab\n",
        "source_path = f'/content/{OUTPUT_FILE}'\n",
        "\n",
        "# Destination path on Google Drive (root directory)\n",
        "destination_path = f'/content/drive/My Drive/{OUTPUT_FILE}'\n",
        "\n",
        "# Move the file\n",
        "shutil.move(source_path, destination_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
