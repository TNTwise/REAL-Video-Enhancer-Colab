{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i7UVVPrHpdW"
      },
      "outputs": [],
      "source": [
        "!rm -rf real-video-enhancer/\n",
        "!git clone https://github.com/tntwise/real-video-enhancer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DAndfQ0KIbx"
      },
      "outputs": [],
      "source": [
        "# https://github.com/TNTwise/real-video-enhancer-models/releases/download/models/ is where all model files for RVE are stored\n",
        "# you can download them from there, or try custom models from https://openmodeldb.info/\n",
        "# Use .pth models for upscaling, and rife .pkl for interpolation, GMFSS and GIMM will also work from the repo\n",
        "!mkdir real-video-enhancer/models/\n",
        "!cd real-video-enhancer/models/ && wget https://github.com/TNTwise/real-video-enhancer-models/releases/download/models/rife4.26.pkl\n",
        "!cd real-video-enhancer/models/ && wget https://github.com/TNTwise/real-video-enhancer-models/releases/download/models/rife4.22.pkl\n",
        "!cd real-video-enhancer/models/ && wget https://github.com/TNTwise/real-video-enhancer-models/releases/download/models/rife4.22-lite.pkl # this is the fastest model\n",
        "!cd real-video-enhancer/models/ && wget https://github.com/TNTwise/real-video-enhancer-models/releases/download/models/2x_ModernSpanimationV2.pth\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhG0D85MIXRA"
      },
      "outputs": [],
      "source": [
        "!pip install  --pre --extra-index-url https://download.pytorch.org/whl/nightly/cu126 -r real-video-enhancer/backend/requirements.txt\n",
        "!cd real-video-enhancer && mkdir bin/ && cd bin && wget https://github.com/TNTwise/real-video-enhancer-models/releases/download/ffmpeg-colab/ffmpeg && chmod +x ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1Kz_PTJb3B_"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "usage: rve-backend.py [-h] [-i INPUT] [-o OUTPUT] [-l OVERLAP] [-b BACKEND]\n",
        "                      [--upscale_model UPSCALE_MODEL]\n",
        "                      [--interpolate_model INTERPOLATE_MODEL]\n",
        "                      [--interpolate_factor INTERPOLATE_FACTOR]\n",
        "                      [--precision PRECISION]\n",
        "                      [--tensorrt_opt_profile TENSORRT_OPT_PROFILE]\n",
        "                      [--scene_detect_method SCENE_DETECT_METHOD]\n",
        "                      [--scene_detect_threshold SCENE_DETECT_THRESHOLD]\n",
        "                      [--overwrite] [--border_detect] [--crf CRF]\n",
        "                      [--video_encoder_preset {libx264,libx265,vp9,av1,x264_vulkan,x264_nvenc,x265_nvenc,av1_nvenc}]\n",
        "                      [--audio_encoder_preset {aac,libmp3lame}]\n",
        "                      [--audio_bitrate AUDIO_BITRATE]\n",
        "                      [--custom_encoder CUSTOM_ENCODER] [--tilesize TILESIZE]\n",
        "                      [--pytorch_gpu_id PYTORCH_GPU_ID]\n",
        "                      [--ncnn_gpu_id NCNN_GPU_ID] [--benchmark] [--UHD_mode]\n",
        "                      [--slomo_mode] [--dynamic_scaled_optical_flow]\n",
        "                      [--ensemble] [--shared_memory_id SHARED_MEMORY_ID]\n",
        "                      [--list_backends] [--paused_file PAUSED_FILE]\n",
        "                      [--upscale_output_resolution UPSCALE_OUTPUT_RESOLUTION]\n",
        "\n",
        "Backend to RVE, used to upscale and interpolate videos\n",
        "\n",
        "options:\n",
        "  -h, --help            show this help message and exit\n",
        "  -i INPUT, --input INPUT\n",
        "                        input video path\n",
        "  -o OUTPUT, --output OUTPUT\n",
        "                        output video path or PIPE\n",
        "  -l OVERLAP, --overlap OVERLAP\n",
        "                        overlap size on tiled rendering (default=10)\n",
        "  -b BACKEND, --backend BACKEND\n",
        "                        backend used to upscale image.\n",
        "                        (pytorch/ncnn/tensorrt/directml, default=pytorch)\n",
        "  --upscale_model UPSCALE_MODEL\n",
        "                        Direct path to upscaling model, will automatically\n",
        "                        upscale if model is valid.\n",
        "  --interpolate_model INTERPOLATE_MODEL\n",
        "                        Direct path to interpolation model, will automatically\n",
        "                        interpolate if model is valid. (Downloadable Options:\n",
        "                        [rife46, rife47, rife415, rife418, rife420, rife422,\n",
        "                        rife422lite]))\n",
        "  --interpolate_factor INTERPOLATE_FACTOR\n",
        "                        Multiplier for interpolation, will round up to nearest\n",
        "                        integer for interpolation but the fps will be correct\n",
        "  --precision PRECISION\n",
        "                        sets precision for model, (auto/float16/float32,\n",
        "                        default=auto)\n",
        "  --tensorrt_opt_profile TENSORRT_OPT_PROFILE\n",
        "                        sets tensorrt optimization profile for model,\n",
        "                        (1/2/3/4/5, default=3)\n",
        "  --scene_detect_method SCENE_DETECT_METHOD\n",
        "                        Scene change detection to avoid interpolating\n",
        "                        transitions. (options=mean, mean_segmented, none) Mean\n",
        "                        segmented splits up an image, and if an arbitrary\n",
        "                        number of segments changes are detected within the\n",
        "                        segments, it will trigger a scene change. (lower\n",
        "                        sensativity thresholds are not recommended)\n",
        "  --scene_detect_threshold SCENE_DETECT_THRESHOLD\n",
        "                        Scene change detection sensitivity, lower number means\n",
        "                        it has a higher chance of detecting scene changes,\n",
        "                        with risk of detecting too many.\n",
        "  --overwrite           Overwrite output video if it already exists.\n",
        "  --border_detect       Detects current borders and removes them, useful for\n",
        "                        removing black bars.\n",
        "  --crf CRF             Constant rate factor for videos, lower setting means\n",
        "                        higher quality.\n",
        "  --video_encoder_preset {libx264,libx265,vp9,av1,x264_vulkan,x264_nvenc,x265_nvenc,av1_nvenc}\n",
        "                        encoder preset that sets default encoder settings\n",
        "                        useful for hardware encoders.\n",
        "  --audio_encoder_preset {aac,libmp3lame}\n",
        "                        encoder preset that sets default encoder settings\n",
        "  --audio_bitrate AUDIO_BITRATE\n",
        "                        bitrate for audio if preset is used\n",
        "  --custom_encoder CUSTOM_ENCODER\n",
        "                        custom encoder\n",
        "  --tilesize TILESIZE   upscale images in smaller chunks, default is the size\n",
        "                        of the input video\n",
        "  --pytorch_gpu_id PYTORCH_GPU_ID\n",
        "                        GPU ID for pytorch backend, default is 0\n",
        "  --ncnn_gpu_id NCNN_GPU_ID\n",
        "                        GPU ID for ncnn backend, default is 0\n",
        "  --benchmark           Benchmark without saving video\n",
        "  --UHD_mode            Lowers the resoltion flow is calculated at, speeding\n",
        "                        up model and saving vram. Helpful for higher\n",
        "                        resultions.\n",
        "  --slomo_mode          Instead of increasing framerate, it will remain the\n",
        "                        same while just increasing the length of the video.\n",
        "  --dynamic_scaled_optical_flow\n",
        "                        Scale the optical flow based on the difference between\n",
        "                        frames, currently only works with the pytorch backend.\n",
        "  --ensemble            Use ensemble when interpolating if the model supports\n",
        "                        it.\n",
        "  --shared_memory_id SHARED_MEMORY_ID\n",
        "                        Memory ID to share preview ons\n",
        "  --list_backends       list out available backends\n",
        "  --paused_file PAUSED_FILE\n",
        "                        File to store paused state (True means paused, False\n",
        "                        means unpaused)\n",
        "  --upscale_output_resolution UPSCALE_OUTPUT_RESOLUTION\n",
        "                        Resolution of output video, this is helpful for 4x\n",
        "                        models when you only want 2x upscaling. Ex:\n",
        "                        (1920x1080)\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzEEIflBLpAG"
      },
      "outputs": [],
      "source": [
        "#example upscale/denoise command\n",
        "# It is recommended to use  --video_encoder_preset x264_nvenc\n",
        "!cd real-video-enhancer/ && python3 backend/rve-backend.py -i ../{INPUT_FILE} -o ../{OUTPUT_FILE} --upscale_model models/{MODEL} --backend pytorch --video_encoder_preset x264_nvenc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example interpoalte command\n",
        "# It is recommended to use  --video_encoder_preset x264_nvenc\n",
        "!cd real-video-enhancer/ && python3 backend/rve-backend.py -i ../{INPUT_FILE} -o ../{OUTPUT_FILE} --interpolate_model models/{MODEL} --backend pytorch --interpolate_factor 2 --video_encoder_preset x264_nvenc"
      ],
      "metadata": {
        "id": "17TmpuaX5BeO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
