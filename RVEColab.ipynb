{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTxXKBNgXXwi"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "usage: rve-backend.py [-h] [-i INPUT] [-o OUTPUT] [-l OVERLAP] [-b BACKEND] [--upscale_model UPSCALE_MODEL]\n",
        "                      [--interpolate_model INTERPOLATE_MODEL] [--interpolate_factor INTERPOLATE_FACTOR]\n",
        "                      [--precision PRECISION] [--tensorrt_opt_profile TENSORRT_OPT_PROFILE]\n",
        "                      [--scene_detect_method SCENE_DETECT_METHOD] [--scene_detect_threshold SCENE_DETECT_THRESHOLD]\n",
        "                      [--overwrite] [--border_detect] [--crf CRF]\n",
        "                      [--video_encoder_preset {libx264,libx265,vp9,av1,prores,ffv1,x264_vulkan,x264_nvenc,x265_nvenc,av1_nvenc,x264_vaapi,x265_vaapi,av1_vaapi}]\n",
        "                      [--video_pixel_format {yuv420p,yuv422p,yuv444p,yuv420p10le,yuv422p10le,yuv444p10le}]\n",
        "                      [--audio_encoder_preset {aac,libmp3lame,opus,copy_audio}]\n",
        "                      [--subtitle_encoder_preset {srt,ass,webvtt,copy_subtitle}] [--audio_bitrate AUDIO_BITRATE]\n",
        "                      [--custom_encoder CUSTOM_ENCODER] [--tilesize TILESIZE] [--pytorch_gpu_id PYTORCH_GPU_ID]\n",
        "                      [--ncnn_gpu_id NCNN_GPU_ID] [--benchmark] [--UHD_mode] [--slomo_mode] [--hdr_mode]\n",
        "                      [--dynamic_scaled_optical_flow] [--ensemble]\n",
        "                      [--preview_shared_memory_id PREVIEW_SHARED_MEMORY_ID] [--output_to_mpv] [--list_backends]\n",
        "                      [--pause_shared_memory_id PAUSE_SHARED_MEMORY_ID]\n",
        "                      [--upscale_output_resolution UPSCALE_OUTPUT_RESOLUTION]\n",
        "\n",
        "Backend to RVE, used to upscale and interpolate videos\n",
        "\n",
        "options:\n",
        "  -h, --help            show this help message and exit\n",
        "  -i INPUT, --input INPUT\n",
        "                        input video path\n",
        "  -o OUTPUT, --output OUTPUT\n",
        "                        output video path or PIPE\n",
        "  -l OVERLAP, --overlap OVERLAP\n",
        "                        overlap size on tiled rendering (default=10)\n",
        "  -b BACKEND, --backend BACKEND\n",
        "                        backend used to upscale image. (pytorch/ncnn/tensorrt/directml, default=pytorch)\n",
        "  --upscale_model UPSCALE_MODEL\n",
        "                        Direct path to upscaling model, will automatically upscale if model is valid.\n",
        "  --interpolate_model INTERPOLATE_MODEL\n",
        "                        Direct path to interpolation model, will automatically interpolate if model is valid.\n",
        "                        (Downloadable Options: [rife46, rife47, rife415, rife418, rife420, rife422, rife422lite]))\n",
        "  --interpolate_factor INTERPOLATE_FACTOR\n",
        "                        Multiplier for interpolation, will round up to nearest integer for interpolation but the fps\n",
        "                        will be correct\n",
        "  --precision PRECISION\n",
        "                        sets precision for model, (auto/float16/float32, default=auto)\n",
        "  --tensorrt_opt_profile TENSORRT_OPT_PROFILE\n",
        "                        sets tensorrt optimization profile for model, (1/2/3/4/5, default=3)\n",
        "  --scene_detect_method SCENE_DETECT_METHOD\n",
        "                        Scene change detection to avoid interpolating transitions. (options=mean, mean_segmented,\n",
        "                        none) Mean segmented splits up an image, and if an arbitrary number of segments changes are\n",
        "                        detected within the segments, it will trigger a scene change. (lower sensativity thresholds\n",
        "                        are not recommended)\n",
        "  --scene_detect_threshold SCENE_DETECT_THRESHOLD\n",
        "                        Scene change detection sensitivity, lower number means it has a higher chance of detecting\n",
        "                        scene changes, with risk of detecting too many.\n",
        "  --overwrite           Overwrite output video if it already exists.\n",
        "  --border_detect       Detects current borders and removes them, useful for removing black bars.\n",
        "  --crf CRF             Constant rate factor for videos, lower setting means higher quality.\n",
        "  --video_encoder_preset {libx264,libx265,vp9,av1,prores,ffv1,x264_vulkan,x264_nvenc,x265_nvenc,av1_nvenc,x264_vaapi,x265_vaapi,av1_vaapi}\n",
        "                        encoder preset that sets default encoder settings useful for hardware encoders.\n",
        "  --video_pixel_format {yuv420p,yuv422p,yuv444p,yuv420p10le,yuv422p10le,yuv444p10le}\n",
        "                        pixel format for output video\n",
        "  --audio_encoder_preset {aac,libmp3lame,opus,copy_audio}\n",
        "                        encoder preset that sets default encoder settings\n",
        "  --subtitle_encoder_preset {srt,ass,webvtt,copy_subtitle}\n",
        "                        encoder preset that sets default encoder settings\n",
        "  --audio_bitrate AUDIO_BITRATE\n",
        "                        bitrate for audio if preset is used\n",
        "  --custom_encoder CUSTOM_ENCODER\n",
        "                        custom encoder\n",
        "  --tilesize TILESIZE   upscale images in smaller chunks, default is the size of the input video\n",
        "  --pytorch_gpu_id PYTORCH_GPU_ID\n",
        "                        GPU ID for pytorch backend, default is 0\n",
        "  --ncnn_gpu_id NCNN_GPU_ID\n",
        "                        GPU ID for ncnn backend, default is 0\n",
        "  --benchmark           Benchmark without saving video\n",
        "  --UHD_mode            Lowers the resoltion flow is calculated at, speeding up model and saving vram. Helpful for\n",
        "                        higher resultions.\n",
        "  --slomo_mode          Instead of increasing framerate, it will remain the same while just increasing the length of\n",
        "                        the video.\n",
        "  --hdr_mode            Appends ffmpeg command to re encode with hdr colorspace\n",
        "  --dynamic_scaled_optical_flow\n",
        "                        Scale the optical flow based on the difference between frames, currently only works with the\n",
        "                        pytorch backend.\n",
        "  --ensemble            Use ensemble when interpolating if the model supports it.\n",
        "  --preview_shared_memory_id PREVIEW_SHARED_MEMORY_ID\n",
        "                        Memory ID to share preview on\n",
        "  --output_to_mpv       Outputs to mpv instead of an output file (requires mpv to be installed)\n",
        "  --list_backends       list out available backends\n",
        "  --pause_shared_memory_id PAUSE_SHARED_MEMORY_ID\n",
        "                        File to store paused state (True means paused, False means unpaused)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJ2xA_TgT80X"
      },
      "outputs": [],
      "source": [
        "# File Settings\n",
        "INPUT_FILE = \"input.mp4\"\n",
        "\n",
        "# this is the output folder that will me exported to the \"My Drive\" folder in Google Drive\n",
        "OUTPUT_FILE = \"output.mkv\" # mkv is recommended, as it supports more codecs {mkv, mp4, avi, mov}\n",
        "\n",
        "# Interpolate Settings\n",
        "\n",
        "# https://github.com/TNTwise/real-video-enhancer-models/releases/tag/models/ is where all model files for RVE are stored\n",
        "# you can download them from there, or try custom models from https://openmodeldb.info/\n",
        "INTERPOLATE = True # {True, False}\n",
        "INTERPOLATE_FACTOR = 2\n",
        "SCENE_DETECT_METHOD = \"pyscenedetect\"\n",
        "SCENE_DETECT_SENSATIVITY = \"3.5\" # {0 - 9.9} lower is more sensative\n",
        "\n",
        "\"\"\"\n",
        "Internal Interpolate Models:\n",
        "rife4.6.pkl - Speed\n",
        "rife4.7.pkl - Smoothness\n",
        "rife4.18.pkl - IRL\n",
        "rife4.22.pkl - Animation\n",
        "rife4.25.pkl - General\n",
        "GMFSS.pkl - Animation\n",
        "GMFSS_PRO.pkl - Animation\n",
        "GIMMVFI_RAFT.pth - IRL\n",
        "\"\"\"\n",
        "INTERPOLATE_MODEL = \"rife4.25.pkl\" # {Internal model, (link to model path)}\n",
        "\n",
        "\n",
        "# Upscale Settings\n",
        "UPSCALE = True # {True, False}\n",
        "\"\"\"\n",
        "4xNomos8k_span_otf_weak.pth - Realistic 4x High Quality Input\n",
        "4xNomos8k_span_otf_medium.pth - Realistic 4x Medium Quality Input\n",
        "4xNomos8k_span_otf_strong.pth - Realistic 4x Low Quality Input\n",
        "2x_BHI_SpanPlusDynamic_Light.pth - Realistic 2x High Quality Input (pytorch only, experimental)\n",
        "\n",
        "2x_ModernSpanimationV2.pth - Animation 2x\n",
        "2x_ModernSpanimationV3.pth - Animation 2x (pytorch only, experimental)\n",
        "2x_AnimeJaNai_V2_Compact_36k.pth - Animation 2x\n",
        "2x_AnimeJaNai_HD_V3_Sharp1_Compact_430k.pth - Animation 2x\n",
        "up2x-latest-conservative.pth - Animation 2x (pytorch only, slow)\n",
        "up3x-latest-conservative.pth - Animation 3x (pytorch only, slow)\n",
        "up4x-latest-conservative.pth - Animation 4x (pytorch only, slow)\n",
        "\"\"\"\n",
        "UPSCALE_MODEL = \"2x_ModernSpanimationV2.pth\" # {(link to model path)}\n",
        "\n",
        "# FFMpeg Settings\n",
        "VIDEO_ENCODER = \"libx264\" # {libx264,libx265,vp9,av1,prores,ffv1,x264_vulkan,x264_nvenc,x265_nvenc}\n",
        "AUDIO_ENCODER = \"copy_audio\" # {aac,libmp3lame,opus,copy_audio}\n",
        "SUBTITLE_ENCODER = \"copy_subtitle\" # {srt,ass,webvtt,copy_subtitle}\n",
        "\n",
        "# Backend Settings\n",
        "BACKEND = \"pytorch\" # {pytorch, tensorrt} TensorRT is fastest, but takes a long time to install deps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTcZMNTeT80a"
      },
      "outputs": [],
      "source": [
        "# will move output file to drive when done for permident storage\n",
        "import os\n",
        "import subprocess\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "# mount drive and move output there for permadent storage\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7i7UVVPrHpdW"
      },
      "outputs": [],
      "source": [
        "!rm -rf real-video-enhancer/\n",
        "!git clone https://github.com/tntwise/real-video-enhancer --branch 2.2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DAndfQ0KIbx"
      },
      "outputs": [],
      "source": [
        "\n",
        "!mkdir real-video-enhancer/models/\n",
        "origdir = os.getcwd()\n",
        "os.chdir(\"real-video-enhancer/models/\")\n",
        "\n",
        "\n",
        "def has_model(model: str):\n",
        "    return model and model.lower() != \"none\"\n",
        "\n",
        "def download_model(model: str):\n",
        "    os.system(f\"wget https://github.com/TNTwise/real-video-enhancer-models/releases/download/models/{model}\")\n",
        "\n",
        "# get interpolate model by extracting the end of the link\n",
        "def download_external_model(model_link : str):\n",
        "        download_model(model_link)\n",
        "        model = model_link.split(r'/')[-1]\n",
        "        return model\n",
        "\n",
        "\n",
        "if INTERPOLATE:\n",
        "    if \"https\" in INTERPOLATE_MODEL:\n",
        "        UPSCALE_MODEL = download_external_model(INTERPOLATE_MODEL, \"interpolate\")\n",
        "    else:\n",
        "        download_model(INTERPOLATE_MODEL)\n",
        "if UPSCALE:\n",
        "    if \"https\" in UPSCALE_MODEL:\n",
        "        UPSCALE_MODEL = download_external_model(UPSCALE_MODEL, \"upscale\")\n",
        "    else:\n",
        "        download_model(UPSCALE_MODEL)\n",
        "\n",
        "\n",
        "os.chdir(origdir)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhG0D85MIXRA"
      },
      "outputs": [],
      "source": [
        "if BACKEND.lower() == 'tensorrt':\n",
        "    !pip install  --pre --extra-index-url https://download.pytorch.org/whl/test/cu126 -r real-video-enhancer/backend/requirements.txt # only install if using tensorrt\n",
        "\n",
        "!mkdir bin/ && cd bin && wget https://github.com/TNTwise/real-video-enhancer-models/releases/download/ffmpeg-colab/ffmpeg && chmod +x ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzEEIflBLpAG"
      },
      "outputs": [],
      "source": [
        "#example upscale/denoise command\n",
        "# It is recommended to use  --video_encoder_preset x264_nvenc\n",
        "def build_backend_command() -> str:\n",
        "    command = ('python3 real-video-enhancer/backend/rve-backend.py'\n",
        "               + f' -i \"{INPUT_FILE}\"'\n",
        "               + f' -o \"{OUTPUT_FILE}\"'\n",
        "               + f' -b {BACKEND} '\n",
        "               + f' --video_encoder_preset {VIDEO_ENCODER}'\n",
        "               + f' --audio_encoder_preset {AUDIO_ENCODER}'\n",
        "               + f' --subtitle_encoder_preset {SUBTITLE_ENCODER}')\n",
        "    if UPSCALE_MODEL:\n",
        "        command += f\" --upscale_model real-video-enhancer/models/{UPSCALE_MODEL} \"\n",
        "    if INTERPOLATE_MODEL:\n",
        "        command += f\" --interpolate_model real-video-enhancer/models/{INTERPOLATE_MODEL} \"\n",
        "        command += f\" --interpolate_factor {INTERPOLATE_FACTOR} \"\n",
        "        command += f\" --scene_detect_method {SCENE_DETECT_METHOD} \"\n",
        "        command += f\" --scene_detect_threshold {SCENE_DETECT_SENSATIVITY} \"\n",
        "\n",
        "    return command\n",
        "\n",
        "with open(\"command.sh\", \"w\") as f:\n",
        "  f.write(build_backend_command())\n",
        "\n",
        "!bash command.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dCKbGtHZT80e"
      },
      "outputs": [],
      "source": [
        "# Source file path in Colab\n",
        "source_path = f'/content/{OUTPUT_FILE}'\n",
        "\n",
        "# Destination path on Google Drive (root directory)\n",
        "destination_path = f'/content/drive/My Drive/{OUTPUT_FILE}'\n",
        "\n",
        "# Move the file\n",
        "shutil.move(source_path, destination_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
